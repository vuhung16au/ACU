{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Regular Expressions Tutorial with Python\n",
        "\n",
        "This Jupyter notebook demonstrates how to use regular expressions in Python for data processing and analysis using the `members.csv` dataset.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Introduction](#introduction)\n",
        "2. [Basic Regex Operations](#basic-regex-operations)\n",
        "3. [Data Loading and Exploration](#data-loading-and-exploration)\n",
        "4. [Email Validation](#email-validation)\n",
        "5. [Date Processing](#date-processing)\n",
        "6. [Address Analysis](#address-analysis)\n",
        "7. [Credit Score Analysis](#credit-score-analysis)\n",
        "8. [Advanced Pattern Matching](#advanced-pattern-matching)\n",
        "9. [Data Validation](#data-validation)\n",
        "10. [Summary and Best Practices](#summary-and-best-practices)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "Regular expressions (regex) are powerful tools for pattern matching and text processing. In Python, we use the `re` module for regex operations. This tutorial will show you how to apply regex patterns to real data analysis tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Regex Operations\n",
        "\n",
        "Let's start with some basic regex operations to understand the fundamentals.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic regex patterns\n",
        "text = \"Hello, my email is john.doe@example.com and my phone is (555) 123-4567\"\n",
        "\n",
        "# Email pattern\n",
        "email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
        "emails = re.findall(email_pattern, text)\n",
        "print(f\"Found emails: {emails}\")\n",
        "\n",
        "# Phone pattern\n",
        "phone_pattern = r'\\(\\d{3}\\)\\s\\d{3}-\\d{4}'\n",
        "phones = re.findall(phone_pattern, text)\n",
        "print(f\"Found phones: {phones}\")\n",
        "\n",
        "# Date pattern\n",
        "date_text = \"Today is 2024-01-15 and tomorrow is 2024-01-16\"\n",
        "date_pattern = r'\\d{4}-\\d{2}-\\d{2}'\n",
        "dates = re.findall(date_pattern, date_text)\n",
        "print(f\"Found dates: {dates}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading and Exploration\n",
        "\n",
        "Let's load our dataset and explore its structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('../members.csv')\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nColumn names:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "print(\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic information about the dataset\n",
        "print(\"Dataset Info:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nBasic Statistics:\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Email Validation\n",
        "\n",
        "Let's validate and analyze email addresses using regex patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Email validation function\n",
        "def validate_email(email):\n",
        "    \"\"\"Validate email format using regex\"\"\"\n",
        "    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
        "    return bool(re.match(pattern, email))\n",
        "\n",
        "# Test email validation\n",
        "sample_emails = df['Email'].head(10).tolist()\n",
        "print(\"Email validation results:\")\n",
        "for email in sample_emails:\n",
        "    is_valid = validate_email(email)\n",
        "    print(f\"{email}: {'✓ Valid' if is_valid else '✗ Invalid'}\")\n",
        "\n",
        "# Count valid emails\n",
        "valid_emails = df['Email'].apply(validate_email).sum()\n",
        "print(f\"\\nValid emails: {valid_emails}/{len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract email domains\n",
        "def extract_domain(email):\n",
        "    \"\"\"Extract domain from email address\"\"\"\n",
        "    pattern = r'@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'\n",
        "    match = re.search(pattern, email)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "# Extract domains\n",
        "df['Email_Domain'] = df['Email'].apply(extract_domain)\n",
        "\n",
        "print(\"Email domains:\")\n",
        "domain_counts = df['Email_Domain'].value_counts()\n",
        "print(domain_counts)\n",
        "\n",
        "# Visualize domain distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "domain_counts.plot(kind='bar')\n",
        "plt.title('Email Domain Distribution')\n",
        "plt.xlabel('Domain')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Date Processing\n",
        "\n",
        "Let's process and analyze date information using regex patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Date validation function\n",
        "def validate_date(date_str):\n",
        "    \"\"\"Validate date format YYYY-MM-DD\"\"\"\n",
        "    pattern = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
        "    if re.match(pattern, date_str):\n",
        "        try:\n",
        "            datetime.strptime(date_str, '%Y-%m-%d')\n",
        "            return True\n",
        "        except ValueError:\n",
        "            return False\n",
        "    return False\n",
        "\n",
        "# Validate dates\n",
        "valid_dates = df['DoB'].apply(validate_date).sum()\n",
        "print(f\"Valid dates: {valid_dates}/{len(df)}\")\n",
        "\n",
        "# Extract birth years\n",
        "def extract_year(date_str):\n",
        "    \"\"\"Extract year from date string\"\"\"\n",
        "    pattern = r'^(\\d{4})'\n",
        "    match = re.match(pattern, date_str)\n",
        "    return int(match.group(1)) if match else None\n",
        "\n",
        "df['Birth_Year'] = df['DoB'].apply(extract_year)\n",
        "print(f\"\\nBirth year range: {df['Birth_Year'].min()} - {df['Birth_Year'].max()}\")\n",
        "\n",
        "# Calculate age\n",
        "current_year = 2024\n",
        "df['Age'] = current_year - df['Birth_Year']\n",
        "print(f\"Age range: {df['Age'].min()} - {df['Age'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize age distribution\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "df['Age'].hist(bins=20, edgecolor='black')\n",
        "plt.title('Age Distribution')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "df['Birth_Year'].hist(bins=20, edgecolor='black')\n",
        "plt.title('Birth Year Distribution')\n",
        "plt.xlabel('Birth Year')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Address Analysis\n",
        "\n",
        "Let's analyze addresses using regex patterns to extract states, cities, and ZIP codes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract state from address\n",
        "def extract_state(address):\n",
        "    \"\"\"Extract state abbreviation from address\"\"\"\n",
        "    pattern = r', ([A-Z]{2}) \\d{5}$'\n",
        "    match = re.search(pattern, address)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "# Extract ZIP code\n",
        "def extract_zip(address):\n",
        "    \"\"\"Extract ZIP code from address\"\"\"\n",
        "    pattern = r'(\\d{5})$'\n",
        "    match = re.search(pattern, address)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "# Extract city\n",
        "def extract_city(address):\n",
        "    \"\"\"Extract city from address\"\"\"\n",
        "    pattern = r'\"([^\"]+), ([^,]+), [A-Z]{2} \\d{5}\"$'\n",
        "    match = re.search(pattern, address)\n",
        "    return match.group(2) if match else None\n",
        "\n",
        "# Apply extraction functions\n",
        "df['State'] = df['Address'].apply(extract_state)\n",
        "df['ZIP'] = df['Address'].apply(extract_zip)\n",
        "df['City'] = df['Address'].apply(extract_city)\n",
        "\n",
        "print(\"State distribution:\")\n",
        "state_counts = df['State'].value_counts()\n",
        "print(state_counts)\n",
        "\n",
        "print(\"\\nCity distribution (top 10):\")\n",
        "city_counts = df['City'].value_counts().head(10)\n",
        "print(city_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize geographic distribution\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "state_counts.plot(kind='bar')\n",
        "plt.title('State Distribution')\n",
        "plt.xlabel('State')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "city_counts.plot(kind='bar')\n",
        "plt.title('Top 10 Cities')\n",
        "plt.xlabel('City')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "df['ZIP'].value_counts().head(10).plot(kind='bar')\n",
        "plt.title('Top 10 ZIP Codes')\n",
        "plt.xlabel('ZIP Code')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Credit Score Analysis\n",
        "\n",
        "Let's analyze credit scores and their patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Credit score validation\n",
        "def validate_credit_score(score):\n",
        "    \"\"\"Validate credit score range\"\"\"\n",
        "    pattern = r'^\\d{3}$'\n",
        "    if re.match(pattern, str(score)):\n",
        "        return 300 <= int(score) <= 850\n",
        "    return False\n",
        "\n",
        "# Validate credit scores\n",
        "valid_scores = df['Credit score'].apply(validate_credit_score).sum()\n",
        "print(f\"Valid credit scores: {valid_scores}/{len(df)}\")\n",
        "\n",
        "# Credit score categories\n",
        "def categorize_credit_score(score):\n",
        "    \"\"\"Categorize credit score into ranges\"\"\"\n",
        "    if score >= 800:\n",
        "        return 'Excellent'\n",
        "    elif score >= 700:\n",
        "        return 'Good'\n",
        "    elif score >= 600:\n",
        "        return 'Fair'\n",
        "    else:\n",
        "        return 'Poor'\n",
        "\n",
        "df['Credit_Category'] = df['Credit score'].apply(categorize_credit_score)\n",
        "\n",
        "print(\"\\nCredit score categories:\")\n",
        "category_counts = df['Credit_Category'].value_counts()\n",
        "print(category_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize credit score distribution\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "df['Credit score'].hist(bins=20, edgecolor='black')\n",
        "plt.title('Credit Score Distribution')\n",
        "plt.xlabel('Credit Score')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "category_counts.plot(kind='bar')\n",
        "plt.title('Credit Score Categories')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "df.boxplot(column='Credit score', by='Gender')\n",
        "plt.title('Credit Score by Gender')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Credit Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Pattern Matching\n",
        "\n",
        "Let's explore more advanced regex patterns and their applications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced name pattern matching\n",
        "def analyze_name_patterns(names):\n",
        "    \"\"\"Analyze name patterns using regex\"\"\"\n",
        "    patterns = {\n",
        "        'First_Last': r'^[A-Z][a-z]+ [A-Z][a-z]+$',\n",
        "        'With_Middle': r'^[A-Z][a-z]+ [A-Z][a-z]+ [A-Z][a-z]+$',\n",
        "        'Hyphenated': r'^[A-Z][a-z]+-[A-Z][a-z]+ [A-Z][a-z]+$',\n",
        "        'Single_Letter': r'^[A-Z]\\.[A-Z][a-z]+$'\n",
        "    }\n",
        "    \n",
        "    results = {}\n",
        "    for pattern_name, pattern in patterns.items():\n",
        "        matches = names.str.match(pattern, na=False).sum()\n",
        "        results[pattern_name] = matches\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Analyze name patterns\n",
        "name_patterns = analyze_name_patterns(df['Full name'])\n",
        "print(\"Name pattern analysis:\")\n",
        "for pattern, count in name_patterns.items():\n",
        "    print(f\"{pattern}: {count}\")\n",
        "\n",
        "# Extract first and last names\n",
        "def extract_first_name(name):\n",
        "    \"\"\"Extract first name\"\"\"\n",
        "    pattern = r'^([A-Z][a-z]+)'\n",
        "    match = re.match(pattern, name)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "def extract_last_name(name):\n",
        "    \"\"\"Extract last name\"\"\"\n",
        "    pattern = r'([A-Z][a-z]+)$'\n",
        "    match = re.search(pattern, name)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "df['First_Name'] = df['Full name'].apply(extract_first_name)\n",
        "df['Last_Name'] = df['Full name'].apply(extract_last_name)\n",
        "\n",
        "print(\"\\nMost common first names:\")\n",
        "print(df['First_Name'].value_counts().head(5))\n",
        "\n",
        "print(\"\\nMost common last names:\")\n",
        "print(df['Last_Name'].value_counts().head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced email pattern analysis\n",
        "def analyze_email_patterns(emails):\n",
        "    \"\"\"Analyze email patterns\"\"\"\n",
        "    patterns = {\n",
        "        'First_Last': r'^[a-zA-Z]+\\.[a-zA-Z]+@',\n",
        "        'First_Initial_Last': r'^[a-zA-Z]+\\.[a-zA-Z]@',\n",
        "        'Numbers': r'[0-9]+@',\n",
        "        'Underscores': r'[a-zA-Z]+_[a-zA-Z]+@',\n",
        "        'Hyphens': r'[a-zA-Z]+-[a-zA-Z]+@'\n",
        "    }\n",
        "    \n",
        "    results = {}\n",
        "    for pattern_name, pattern in patterns.items():\n",
        "        matches = emails.str.match(pattern, na=False).sum()\n",
        "        results[pattern_name] = matches\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Analyze email patterns\n",
        "email_patterns = analyze_email_patterns(df['Email'])\n",
        "print(\"Email pattern analysis:\")\n",
        "for pattern, count in email_patterns.items():\n",
        "    print(f\"{pattern}: {count}\")\n",
        "\n",
        "# Visualize email patterns\n",
        "plt.figure(figsize=(10, 6))\n",
        "pattern_names = list(email_patterns.keys())\n",
        "pattern_counts = list(email_patterns.values())\n",
        "plt.bar(pattern_names, pattern_counts)\n",
        "plt.title('Email Pattern Distribution')\n",
        "plt.xlabel('Pattern Type')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Validation\n",
        "\n",
        "Let's create comprehensive data validation using regex patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive data validation\n",
        "def validate_dataset(df):\n",
        "    \"\"\"Validate entire dataset using regex patterns\"\"\"\n",
        "    validation_results = {\n",
        "        'Email': df['Email'].apply(validate_email).sum(),\n",
        "        'Date': df['DoB'].apply(validate_date).sum(),\n",
        "        'Credit_Score': df['Credit score'].apply(validate_credit_score).sum(),\n",
        "        'Name': df['Full name'].str.match(r'^[A-Z][a-z]+ [A-Z][a-z]+$', na=False).sum(),\n",
        "        'Gender': df['Gender'].isin(['Male', 'Female']).sum(),\n",
        "        'Height': df['Height (cm)'].between(100, 250).sum(),\n",
        "        'Weight': df['Weight (kg)'].between(30, 200).sum()\n",
        "    }\n",
        "    \n",
        "    return validation_results\n",
        "\n",
        "# Run validation\n",
        "validation_results = validate_dataset(df)\n",
        "total_records = len(df)\n",
        "\n",
        "print(\"Data Validation Results:\")\n",
        "print(\"=\" * 40)\n",
        "for field, valid_count in validation_results.items():\n",
        "    percentage = (valid_count / total_records) * 100\n",
        "    print(f\"{field:15}: {valid_count:3}/{total_records} ({percentage:5.1f}%)\")\n",
        "\n",
        "# Calculate overall data quality score\n",
        "overall_score = sum(validation_results.values()) / (len(validation_results) * total_records) * 100\n",
        "print(f\"\\nOverall Data Quality Score: {overall_score:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize validation results\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "fields = list(validation_results.keys())\n",
        "valid_counts = list(validation_results.values())\n",
        "percentages = [(count / total_records) * 100 for count in valid_counts]\n",
        "\n",
        "bars = plt.bar(fields, percentages)\n",
        "plt.title('Data Validation Results')\n",
        "plt.xlabel('Field')\n",
        "plt.ylabel('Valid Percentage (%)')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Add percentage labels on bars\n",
        "for bar, percentage in zip(bars, percentages):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
        "             f'{percentage:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.pie(percentages, labels=fields, autopct='%1.1f%%')\n",
        "plt.title('Data Quality Distribution')\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.hist(df['Credit score'], bins=20, edgecolor='black', alpha=0.7)\n",
        "plt.title('Credit Score Distribution')\n",
        "plt.xlabel('Credit Score')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "df['Age'].hist(bins=20, edgecolor='black', alpha=0.7)\n",
        "plt.title('Age Distribution')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Best Practices\n",
        "\n",
        "Let's summarize what we've learned and provide some best practices for using regular expressions in data analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics\n",
        "print(\"Dataset Summary:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Total records: {len(df)}\")\n",
        "print(f\"Valid emails: {validation_results['Email']}/{len(df)}\")\n",
        "print(f\"Valid dates: {validation_results['Date']}/{len(df)}\")\n",
        "print(f\"Valid credit scores: {validation_results['Credit_Score']}/{len(df)}\")\n",
        "print(f\"Valid names: {validation_results['Name']}/{len(df)}\")\n",
        "print(f\"Valid genders: {validation_results['Gender']}/{len(df)}\")\n",
        "print(f\"Valid heights: {validation_results['Height']}/{len(df)}\")\n",
        "print(f\"Valid weights: {validation_results['Weight']}/{len(df)}\")\n",
        "\n",
        "print(f\"\\nOverall data quality: {overall_score:.1f}%\")\n",
        "\n",
        "# Data insights\n",
        "print(\"\\nData Insights:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Average credit score: {df['Credit score'].mean():.1f}\")\n",
        "print(f\"Average age: {df['Age'].mean():.1f}\")\n",
        "print(f\"Average height: {df['Height (cm)'].mean():.1f} cm\")\n",
        "print(f\"Average weight: {df['Weight (kg)'].mean():.1f} kg\")\n",
        "print(f\"Gender distribution: {df['Gender'].value_counts().to_dict()}\")\n",
        "print(f\"Most common state: {df['State'].mode().iloc[0] if not df['State'].mode().empty else 'N/A'}\")\n",
        "print(f\"Most common email domain: {df['Email_Domain'].mode().iloc[0] if not df['Email_Domain'].mode().empty else 'N/A'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Practices for Regex in Data Analysis\n",
        "\n",
        "1. **Always validate your patterns**: Test regex patterns on sample data before applying to large datasets\n",
        "2. **Use raw strings**: Prefix regex patterns with `r` to avoid escaping issues\n",
        "3. **Handle edge cases**: Consider empty strings, null values, and unexpected formats\n",
        "4. **Document your patterns**: Add comments to complex regex patterns\n",
        "5. **Test performance**: Some patterns can be slow on large datasets\n",
        "6. **Use built-in functions**: Leverage pandas string methods when possible\n",
        "7. **Validate results**: Always verify your regex results make sense\n",
        "8. **Consider alternatives**: Sometimes string methods are more efficient than regex\n",
        "\n",
        "## Common Regex Patterns for Data Analysis\n",
        "\n",
        "- **Email**: `r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'`\n",
        "- **Phone**: `r'\\(\\d{3}\\)\\s\\d{3}-\\d{4}'`\n",
        "- **Date**: `r'^\\d{4}-\\d{2}-\\d{2}$'`\n",
        "- **ZIP Code**: `r'^\\d{5}(-\\d{4})?$'`\n",
        "- **Credit Card**: `r'^\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}$'`\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Regular expressions are powerful tools for data cleaning, validation, and analysis. When used correctly, they can significantly improve your data processing workflows. Remember to always test your patterns and consider the performance implications for large datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final demonstration: Complex pattern matching\n",
        "print(\"Final Demonstration: Complex Pattern Matching\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Find people with specific characteristics\n",
        "def find_high_performers(df):\n",
        "    \"\"\"Find people with high credit scores and specific characteristics\"\"\"\n",
        "    criteria = (\n",
        "        (df['Credit score'] > 800) &\n",
        "        (df['Age'] >= 25) &\n",
        "        (df['Age'] <= 40) &\n",
        "        (df['Height (cm)'] > 170)\n",
        "    )\n",
        "    return df[criteria]\n",
        "\n",
        "high_performers = find_high_performers(df)\n",
        "print(f\"High performers found: {len(high_performers)}\")\n",
        "print(\"\\nHigh performers:\")\n",
        "print(high_performers[['Full name', 'Email', 'Credit score', 'Age', 'Height (cm)']].head())\n",
        "\n",
        "print(\"\\nTutorial completed successfully!\")\n",
        "print(\"You've learned how to use regular expressions for data analysis in Python.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c2790e",
   "metadata": {},
   "source": [
    "# OpenCV Color Processing Tutorial\n",
    "\n",
    "This notebook explores color space operations, histogram processing, and color enhancement techniques in OpenCV.\n",
    "\n",
    "## Contents\n",
    "1. [Setup and Installation](#setup)\n",
    "2. [Color Space Conversions](#color-spaces)\n",
    "3. [Histogram Analysis](#histograms)\n",
    "4. [Color Enhancement](#enhancement)\n",
    "5. [Color-based Segmentation](#segmentation)\n",
    "6. [Practical Applications](#applications)\n",
    "7. [Exercises](#exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0476657a",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation {#setup}\n",
    "\n",
    "First, let's import the necessary libraries and our custom modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467203f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "# !pip install opencv-python numpy matplotlib\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Add our source directory to Python path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our custom modules\n",
    "from color_processing import color_spaces, histogram, color_enhancement\n",
    "from basic_operations import image_io, display\n",
    "from utils import visualization\n",
    "\n",
    "print(\"✅ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e370a8d8",
   "metadata": {},
   "source": [
    "# Create Sample Colorful Image\n",
    "\n",
    "Let's create a colorful test image to demonstrate color processing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4650f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample image\n",
    "image_path = '../sample_images/original/demo_image.jpg'\n",
    "if os.path.exists(image_path):\n",
    "    image = image_io.load_image(image_path)\n",
    "else:\n",
    "    # Create a colorful demo image\n",
    "    image = np.zeros((400, 600, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Create color gradient background\n",
    "    for i in range(400):\n",
    "        for j in range(600):\n",
    "            image[i, j] = [\n",
    "                int(255 * (i / 400)),           # Red gradient\n",
    "                int(255 * (j / 600)),           # Green gradient\n",
    "                int(255 * ((i + j) / 1000))     # Blue gradient\n",
    "            ]\n",
    "    \n",
    "    # Add solid color shapes\n",
    "    cv2.rectangle(image, (50, 50), (150, 150), (255, 0, 0), -1)    # Red\n",
    "    cv2.rectangle(image, (200, 50), (300, 150), (0, 255, 0), -1)   # Green\n",
    "    cv2.rectangle(image, (350, 50), (450, 150), (0, 0, 255), -1)   # Blue\n",
    "    \n",
    "    cv2.circle(image, (100, 250), 50, (255, 255, 0), -1)           # Cyan\n",
    "    cv2.circle(image, (250, 250), 50, (255, 0, 255), -1)           # Magenta\n",
    "    cv2.circle(image, (400, 250), 50, (0, 255, 255), -1)           # Yellow\n",
    "    \n",
    "    # Add white and black regions\n",
    "    cv2.rectangle(image, (500, 200), (550, 250), (255, 255, 255), -1)  # White\n",
    "    cv2.rectangle(image, (500, 300), (550, 350), (0, 0, 0), -1)        # Black\n",
    "\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Image dtype: {image.dtype}\")\n",
    "\n",
    "# Display the test image\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Colorful Test Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0425b6a",
   "metadata": {},
   "source": [
    "## 2. Color Space Conversions {#color-spaces}\n",
    "\n",
    "Different color spaces are useful for different types of image processing tasks.\n",
    "\n",
    "### 2.1 RGB to HSV Conversion\n",
    "HSV (Hue, Saturation, Value) separates color information from intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caead7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to HSV\n",
    "hsv_image = color_spaces.rgb_to_hsv(image)\n",
    "\n",
    "# Split HSV channels\n",
    "h, s, v = cv2.split(hsv_image)\n",
    "\n",
    "# Display RGB and HSV\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# RGB image and channels\n",
    "axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original RGB')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# RGB channels\n",
    "b, g, r = cv2.split(image)\n",
    "axes[0, 1].imshow(r, cmap='Reds')\n",
    "axes[0, 1].set_title('Red Channel')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(g, cmap='Greens')\n",
    "axes[0, 2].set_title('Green Channel')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[0, 3].imshow(b, cmap='Blues')\n",
    "axes[0, 3].set_title('Blue Channel')\n",
    "axes[0, 3].axis('off')\n",
    "\n",
    "# HSV image and channels\n",
    "axes[1, 0].imshow(cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB))\n",
    "axes[1, 0].set_title('HSV Image')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(h, cmap='hsv')\n",
    "axes[1, 1].set_title('Hue Channel')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(s, cmap='gray')\n",
    "axes[1, 2].set_title('Saturation Channel')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "axes[1, 3].imshow(v, cmap='gray')\n",
    "axes[1, 3].set_title('Value Channel')\n",
    "axes[1, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"HSV ranges - H: {h.min()}-{h.max()}, S: {s.min()}-{s.max()}, V: {v.min()}-{v.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ee9d0",
   "metadata": {},
   "source": [
    "### 2.2 LAB Color Space\n",
    "LAB color space is perceptually uniform and good for color difference calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef45f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to LAB\n",
    "lab_image = color_spaces.rgb_to_lab(image)\n",
    "\n",
    "# Split LAB channels\n",
    "l, a, b_lab = cv2.split(lab_image)\n",
    "\n",
    "# Display LAB channels\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original RGB')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(l, cmap='gray')\n",
    "axes[1].set_title('L* (Lightness)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(a, cmap='RdYlGn_r')\n",
    "axes[2].set_title('a* (Green-Red)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(b_lab, cmap='YlOrBl_r')\n",
    "axes[3].set_title('b* (Blue-Yellow)')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"LAB ranges - L: {l.min()}-{l.max()}, a: {a.min()}-{a.max()}, b: {b_lab.min()}-{b_lab.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c817a",
   "metadata": {},
   "source": [
    "### 2.3 Grayscale Conversions\n",
    "Different methods for converting to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455762ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different grayscale conversion methods\n",
    "gray_opencv = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray_average = color_spaces.rgb_to_gray_average(image)\n",
    "gray_luminance = color_spaces.rgb_to_gray_luminance(image)\n",
    "gray_custom = color_spaces.rgb_to_gray_custom(image, weights=[0.2, 0.7, 0.1])\n",
    "\n",
    "# Display different grayscale methods\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Color')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(gray_opencv, cmap='gray')\n",
    "axes[1].set_title('OpenCV Default\\n(0.299R + 0.587G + 0.114B)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(gray_average, cmap='gray')\n",
    "axes[2].set_title('Average\\n(R + G + B) / 3')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(gray_luminance, cmap='gray')\n",
    "axes[3].set_title('Luminance\\n(0.21R + 0.72G + 0.07B)')\n",
    "axes[3].axis('off')\n",
    "\n",
    "axes[4].imshow(gray_custom, cmap='gray')\n",
    "axes[4].set_title('Custom Weights\\n(0.2R + 0.7G + 0.1B)')\n",
    "axes[4].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501da5c",
   "metadata": {},
   "source": [
    "## 3. Histogram Analysis {#histograms}\n",
    "\n",
    "Histograms show the distribution of pixel intensities in images.\n",
    "\n",
    "### 3.1 Color Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa7f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display color histograms\n",
    "hist_b = histogram.calculate_histogram(image, channel=0)  # Blue\n",
    "hist_g = histogram.calculate_histogram(image, channel=1)  # Green\n",
    "hist_r = histogram.calculate_histogram(image, channel=2)  # Red\n",
    "\n",
    "# Plot histograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Original image\n",
    "axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Individual channel histograms\n",
    "axes[0, 1].plot(hist_r, color='red', alpha=0.7, label='Red')\n",
    "axes[0, 1].plot(hist_g, color='green', alpha=0.7, label='Green')\n",
    "axes[0, 1].plot(hist_b, color='blue', alpha=0.7, label='Blue')\n",
    "axes[0, 1].set_title('RGB Histograms')\n",
    "axes[0, 1].set_xlabel('Pixel Intensity')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Separate histograms\n",
    "axes[1, 0].hist(image[:,:,2].ravel(), bins=256, range=[0,256], color='red', alpha=0.7)\n",
    "axes[1, 0].set_title('Red Channel Histogram')\n",
    "axes[1, 0].set_xlabel('Pixel Intensity')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1, 1].hist(image[:,:,1].ravel(), bins=256, range=[0,256], color='green', alpha=0.7)\n",
    "axes[1, 1].set_title('Green Channel Histogram')\n",
    "axes[1, 1].set_xlabel('Pixel Intensity')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print histogram statistics\n",
    "print(\"Histogram Statistics:\")\n",
    "print(f\"Red channel - Mean: {np.mean(image[:,:,2]):.1f}, Std: {np.std(image[:,:,2]):.1f}\")\n",
    "print(f\"Green channel - Mean: {np.mean(image[:,:,1]):.1f}, Std: {np.std(image[:,:,1]):.1f}\")\n",
    "print(f\"Blue channel - Mean: {np.mean(image[:,:,0]):.1f}, Std: {np.std(image[:,:,0]):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20cdf87",
   "metadata": {},
   "source": [
    "### 3.2 Histogram Equalization\n",
    "Enhancing contrast by equalizing the intensity distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279ab932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply histogram equalization\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Standard histogram equalization\n",
    "equalized = histogram.histogram_equalization(gray_image)\n",
    "\n",
    "# Color histogram equalization (in LAB space)\n",
    "lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "lab[:,:,0] = cv2.equalizeHist(lab[:,:,0])  # Equalize L channel\n",
    "equalized_color = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Grayscale equalization\n",
    "axes[0, 0].imshow(gray_image, cmap='gray')\n",
    "axes[0, 0].set_title('Original Grayscale')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(equalized, cmap='gray')\n",
    "axes[0, 1].set_title('Histogram Equalized')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Histograms\n",
    "axes[0, 2].hist(gray_image.ravel(), bins=256, range=[0,256], alpha=0.7, label='Original')\n",
    "axes[0, 2].hist(equalized.ravel(), bins=256, range=[0,256], alpha=0.7, label='Equalized')\n",
    "axes[0, 2].set_title('Histograms Comparison')\n",
    "axes[0, 2].legend()\n",
    "\n",
    "# Color equalization\n",
    "axes[1, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title('Original Color')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(equalized_color, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title('Color Histogram Equalized\\n(L channel in LAB)')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Compare L channel histograms\n",
    "lab_orig = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "axes[1, 2].hist(lab_orig[:,:,0].ravel(), bins=256, range=[0,256], alpha=0.7, label='Original L')\n",
    "axes[1, 2].hist(lab[:,:,0].ravel(), bins=256, range=[0,256], alpha=0.7, label='Equalized L')\n",
    "axes[1, 2].set_title('L Channel Histograms')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd8d9b",
   "metadata": {},
   "source": [
    "### 3.3 CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "Adaptive histogram equalization that prevents over-amplification of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ab724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply CLAHE\n",
    "clahe_gray = histogram.clahe_enhancement(gray_image, clip_limit=2.0, tile_grid_size=(8, 8))\n",
    "\n",
    "# CLAHE on color image (LAB space)\n",
    "lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "lab[:,:,0] = clahe.apply(lab[:,:,0])\n",
    "clahe_color = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# Compare different enhancement methods\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Grayscale comparison\n",
    "axes[0, 0].imshow(gray_image, cmap='gray')\n",
    "axes[0, 0].set_title('Original Grayscale')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(equalized, cmap='gray')\n",
    "axes[0, 1].set_title('Standard Histogram Equalization')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(clahe_gray, cmap='gray')\n",
    "axes[0, 2].set_title('CLAHE')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Color comparison\n",
    "axes[1, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title('Original Color')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(equalized_color, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title('Standard Equalization')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(cv2.cvtColor(clahe_color, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 2].set_title('CLAHE')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69095ae",
   "metadata": {},
   "source": [
    "## 4. Color Enhancement {#enhancement}\n",
    "\n",
    "Techniques for improving color appearance and adjusting color properties.\n",
    "\n",
    "### 4.1 Brightness and Contrast Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c60b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust brightness and contrast\n",
    "bright_image = color_enhancement.adjust_brightness(image, beta=50)\n",
    "contrast_image = color_enhancement.adjust_contrast(image, alpha=1.5)\n",
    "bright_contrast_image = color_enhancement.adjust_brightness_contrast(image, alpha=1.3, beta=30)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(bright_image, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('Brightness +50')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(cv2.cvtColor(contrast_image, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title('Contrast ×1.5')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(bright_contrast_image, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title('Brightness +30, Contrast ×1.3')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd0308",
   "metadata": {},
   "source": [
    "### 4.2 Gamma Correction\n",
    "Adjusting image gamma for better display or perception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37561d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply gamma correction\n",
    "gamma_low = color_enhancement.gamma_correction(image, gamma=0.5)   # Brighten\n",
    "gamma_high = color_enhancement.gamma_correction(image, gamma=2.0)  # Darken\n",
    "\n",
    "# Display gamma correction results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(gamma_low, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Gamma = 0.5 (Brighter)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Original (Gamma = 1.0)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(gamma_high, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Gamma = 2.0 (Darker)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show gamma curve\n",
    "gamma_values = np.linspace(0, 1, 256)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "for gamma in [0.5, 1.0, 2.0]:\n",
    "    corrected = np.power(gamma_values, 1.0/gamma)\n",
    "    ax.plot(gamma_values, corrected, label=f'γ = {gamma}')\n",
    "\n",
    "ax.set_xlabel('Input Intensity')\n",
    "ax.set_ylabel('Output Intensity')\n",
    "ax.set_title('Gamma Correction Curves')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0090f5e7",
   "metadata": {},
   "source": [
    "### 4.3 White Balance Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed98eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate color temperature shifts and correct them\n",
    "warm_image = color_enhancement.adjust_color_temperature(image, temperature=1.2)  # Warmer\n",
    "cool_image = color_enhancement.adjust_color_temperature(image, temperature=0.8)  # Cooler\n",
    "\n",
    "# Apply white balance correction\n",
    "wb_corrected = color_enhancement.white_balance_correction(warm_image)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(warm_image, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('Warm Temperature')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(cv2.cvtColor(cool_image, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title('Cool Temperature')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(wb_corrected, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title('White Balance Corrected')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72261031",
   "metadata": {},
   "source": [
    "## 5. Color-based Segmentation {#segmentation}\n",
    "\n",
    "Using color information to segment objects from the background.\n",
    "\n",
    "### 5.1 HSV Color Range Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe3ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to HSV for color segmentation\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define color ranges for different objects\n",
    "color_ranges = {\n",
    "    'Red': ([0, 50, 50], [10, 255, 255]),     # Red objects\n",
    "    'Green': ([40, 50, 50], [80, 255, 255]),   # Green objects\n",
    "    'Blue': ([100, 50, 50], [130, 255, 255]),  # Blue objects\n",
    "    'Yellow': ([15, 50, 50], [35, 255, 255]),  # Yellow objects\n",
    "}\n",
    "\n",
    "# Create masks for each color\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Original image\n",
    "axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Color masks\n",
    "mask_positions = [(0, 1), (0, 2), (1, 0), (1, 1)]\n",
    "colors = ['Red', 'Green', 'Blue', 'Yellow']\n",
    "\n",
    "combined_mask = np.zeros(hsv.shape[:2], dtype=np.uint8)\n",
    "\n",
    "for i, color in enumerate(colors):\n",
    "    if i < 4:\n",
    "        lower, upper = color_ranges[color]\n",
    "        mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
    "        \n",
    "        # Apply mask to original image\n",
    "        segmented = cv2.bitwise_and(image, image, mask=mask)\n",
    "        \n",
    "        row, col = mask_positions[i]\n",
    "        axes[row, col].imshow(cv2.cvtColor(segmented, cv2.COLOR_BGR2RGB))\n",
    "        axes[row, col].set_title(f'{color} Objects')\n",
    "        axes[row, col].axis('off')\n",
    "        \n",
    "        # Add to combined mask\n",
    "        combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
    "\n",
    "# Combined segmentation\n",
    "combined_segmented = cv2.bitwise_and(image, image, mask=combined_mask)\n",
    "axes[1, 2].imshow(cv2.cvtColor(combined_segmented, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 2].set_title('All Colors Combined')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7dc03",
   "metadata": {},
   "source": [
    "### 5.2 K-Means Color Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eeb70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-means clustering for color quantization\n",
    "def color_quantization_kmeans(image, k=8):\n",
    "    \"\"\"Reduce number of colors using K-means clustering.\"\"\"\n",
    "    # Reshape image to be a list of pixels\n",
    "    pixel_values = image.reshape((-1, 3))\n",
    "    pixel_values = np.float32(pixel_values)\n",
    "    \n",
    "    # Define criteria and apply K-means\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)\n",
    "    _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    # Convert back to uint8 and reshape\n",
    "    centers = np.uint8(centers)\n",
    "    segmented_data = centers[labels.flatten()]\n",
    "    segmented_image = segmented_data.reshape(image.shape)\n",
    "    \n",
    "    return segmented_image, centers\n",
    "\n",
    "# Apply K-means with different K values\n",
    "k_values = [2, 4, 8, 16]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for i, k in enumerate(k_values):\n",
    "    quantized, centers = color_quantization_kmeans(image, k)\n",
    "    \n",
    "    row, col = i // 2, i % 2\n",
    "    axes[row, col].imshow(cv2.cvtColor(quantized, cv2.COLOR_BGR2RGB))\n",
    "    axes[row, col].set_title(f'K-means Clustering (K={k})')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show color palette for K=8\n",
    "quantized_8, centers_8 = color_quantization_kmeans(image, 8)\n",
    "\n",
    "# Create color palette\n",
    "palette = np.zeros((50, 400, 3), dtype=np.uint8)\n",
    "for i, color in enumerate(centers_8):\n",
    "    start_x = i * 50\n",
    "    end_x = (i + 1) * 50\n",
    "    palette[:, start_x:end_x] = color[::-1]  # BGR to RGB\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(palette)\n",
    "plt.title('Extracted Color Palette (K=8)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Extracted colors (RGB):\")\n",
    "for i, color in enumerate(centers_8):\n",
    "    print(f\"Color {i+1}: RGB({color[2]}, {color[1]}, {color[0]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd92da",
   "metadata": {},
   "source": [
    "## 6. Practical Applications {#applications}\n",
    "\n",
    "### 6.1 Skin Tone Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9274e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image with skin-like colors for demonstration\n",
    "skin_image = np.zeros((300, 400, 3), dtype=np.uint8)\n",
    "\n",
    "# Add various skin tones\n",
    "skin_colors = [\n",
    "    (220, 180, 140),  # Light skin\n",
    "    (200, 160, 120),  # Medium-light skin  \n",
    "    (180, 140, 100),  # Medium skin\n",
    "    (160, 120, 80),   # Medium-dark skin\n",
    "    (140, 100, 60),   # Dark skin\n",
    "]\n",
    "\n",
    "for i, color in enumerate(skin_colors):\n",
    "    x = i * 80\n",
    "    cv2.rectangle(skin_image, (x, 50), (x+70, 150), color, -1)\n",
    "\n",
    "# Add non-skin colors\n",
    "cv2.rectangle(skin_image, (50, 200), (120, 250), (0, 255, 0), -1)   # Green\n",
    "cv2.rectangle(skin_image, (150, 200), (220, 250), (0, 0, 255), -1)  # Red\n",
    "cv2.rectangle(skin_image, (250, 200), (320, 250), (255, 0, 0), -1)  # Blue\n",
    "\n",
    "# Skin detection using multiple color spaces\n",
    "def detect_skin_multichannel(image):\n",
    "    \"\"\"Detect skin using multiple color space rules.\"\"\"\n",
    "    # Convert to different color spaces\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # HSV skin detection\n",
    "    lower_hsv = np.array([0, 20, 70])\n",
    "    upper_hsv = np.array([20, 255, 255])\n",
    "    mask_hsv = cv2.inRange(hsv, lower_hsv, upper_hsv)\n",
    "    \n",
    "    # YCrCb skin detection\n",
    "    lower_ycrcb = np.array([0, 133, 77])\n",
    "    upper_ycrcb = np.array([255, 173, 127])\n",
    "    mask_ycrcb = cv2.inRange(ycrcb, lower_ycrcb, upper_ycrcb)\n",
    "    \n",
    "    # Combine masks\n",
    "    skin_mask = cv2.bitwise_and(mask_hsv, mask_ycrcb)\n",
    "    \n",
    "    return skin_mask\n",
    "\n",
    "# Apply skin detection\n",
    "skin_mask = detect_skin_multichannel(skin_image)\n",
    "skin_detected = cv2.bitwise_and(skin_image, skin_image, mask=skin_mask)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(skin_image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Test Image with Skin Tones')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(skin_mask, cmap='gray')\n",
    "axes[1].set_title('Skin Detection Mask')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(skin_detected, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Detected Skin Regions')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05d12f4",
   "metadata": {},
   "source": [
    "### 6.2 Color-based Object Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b90981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate object tracking by color\n",
    "def create_tracking_sequence():\n",
    "    \"\"\"Create a sequence of images with a moving colored object.\"\"\"\n",
    "    frames = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        frame = np.zeros((300, 400, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Add background pattern\n",
    "        for y in range(0, 300, 20):\n",
    "            for x in range(0, 400, 20):\n",
    "                if (x + y) % 40 == 0:\n",
    "                    cv2.rectangle(frame, (x, y), (x+10, y+10), (50, 50, 50), -1)\n",
    "        \n",
    "        # Add moving object (red circle)\n",
    "        center_x = 50 + i * 70\n",
    "        center_y = 150 + int(30 * np.sin(i * 0.5))\n",
    "        cv2.circle(frame, (center_x, center_y), 25, (0, 0, 255), -1)\n",
    "        \n",
    "        # Add noise objects\n",
    "        cv2.circle(frame, (100, 250), 15, (0, 255, 0), -1)  # Green distractor\n",
    "        cv2.circle(frame, (300, 80), 20, (255, 0, 0), -1)   # Blue distractor\n",
    "        \n",
    "        frames.append(frame)\n",
    "    \n",
    "    return frames\n",
    "\n",
    "# Create tracking sequence\n",
    "tracking_frames = create_tracking_sequence()\n",
    "\n",
    "# Track red object\n",
    "def track_red_object(image):\n",
    "    \"\"\"Track red object using color segmentation.\"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Red color range (accounting for hue wrap-around)\n",
    "    lower_red1 = np.array([0, 120, 70])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([170, 120, 70])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "    \n",
    "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Find largest contour\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Get bounding box\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        center = (x + w//2, y + h//2)\n",
    "        \n",
    "        return center, (x, y, w, h)\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "# Track object through sequence\n",
    "tracking_results = []\n",
    "fig, axes = plt.subplots(1, len(tracking_frames), figsize=(20, 4))\n",
    "\n",
    "for i, frame in enumerate(tracking_frames):\n",
    "    center, bbox = track_red_object(frame)\n",
    "    \n",
    "    # Draw tracking result\n",
    "    result_frame = frame.copy()\n",
    "    if center and bbox:\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(result_frame, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "        cv2.circle(result_frame, center, 5, (255, 255, 0), -1)\n",
    "        cv2.putText(result_frame, f'Frame {i+1}', (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        \n",
    "        tracking_results.append(center)\n",
    "    \n",
    "    axes[i].imshow(cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB))\n",
    "    axes[i].set_title(f'Frame {i+1}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot tracking trajectory\n",
    "if tracking_results:\n",
    "    x_coords = [center[0] for center in tracking_results]\n",
    "    y_coords = [center[1] for center in tracking_results]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x_coords, y_coords, 'ro-', linewidth=2, markersize=8)\n",
    "    plt.title('Object Tracking Trajectory')\n",
    "    plt.xlabel('X Coordinate')\n",
    "    plt.ylabel('Y Coordinate')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.gca().invert_yaxis()  # Invert Y axis to match image coordinates\n",
    "    \n",
    "    # Annotate frames\n",
    "    for i, (x, y) in enumerate(tracking_results):\n",
    "        plt.annotate(f'F{i+1}', (x, y), xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Tracking Results:\")\n",
    "    for i, center in enumerate(tracking_results):\n",
    "        print(f\"Frame {i+1}: Object center at {center}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c492dd8d",
   "metadata": {},
   "source": [
    "## 7. Exercises {#exercises}\n",
    "\n",
    "Try these exercises to practice color processing techniques:\n",
    "\n",
    "### Exercise 1: Custom Color Space Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2947f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Create a custom color space\n",
    "def rgb_to_custom_space(image):\n",
    "    \"\"\"Convert RGB to a custom color space that emphasizes certain features.\"\"\"\n",
    "    # Custom transformation that emphasizes color differences\n",
    "    r, g, b = cv2.split(image.astype(np.float32))\n",
    "    \n",
    "    # Channel 1: Color intensity (similar to luminance but different weights)\n",
    "    intensity = 0.4 * r + 0.3 * g + 0.3 * b\n",
    "    \n",
    "    # Channel 2: Red-Green difference (chrominance)\n",
    "    rg_diff = (r - g) + 128  # Add offset to handle negative values\n",
    "    \n",
    "    # Channel 3: Blue-Yellow difference (chrominance)\n",
    "    by_diff = (b - (r + g) / 2) + 128  # Add offset\n",
    "    \n",
    "    # Normalize to 0-255 range\n",
    "    intensity = np.clip(intensity, 0, 255)\n",
    "    rg_diff = np.clip(rg_diff, 0, 255)\n",
    "    by_diff = np.clip(by_diff, 0, 255)\n",
    "    \n",
    "    custom_image = cv2.merge([intensity, rg_diff, by_diff]).astype(np.uint8)\n",
    "    return custom_image\n",
    "\n",
    "# Apply custom color space conversion\n",
    "custom_space = rgb_to_custom_space(image)\n",
    "custom_channels = cv2.split(custom_space)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Original and custom space\n",
    "axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original RGB')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(custom_space)\n",
    "axes[0, 1].set_title('Custom Color Space')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Custom space channels\n",
    "axes[0, 2].imshow(custom_channels[0], cmap='gray')\n",
    "axes[0, 2].set_title('Intensity Channel')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(custom_channels[1], cmap='RdGn')\n",
    "axes[1, 0].set_title('Red-Green Difference')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(custom_channels[2], cmap='RdYlBu')\n",
    "axes[1, 1].set_title('Blue-Yellow Difference')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Channel statistics\n",
    "axes[1, 2].hist(custom_channels[0].ravel(), bins=50, alpha=0.7, label='Intensity')\n",
    "axes[1, 2].hist(custom_channels[1].ravel(), bins=50, alpha=0.7, label='R-G Diff')\n",
    "axes[1, 2].hist(custom_channels[2].ravel(), bins=50, alpha=0.7, label='B-Y Diff')\n",
    "axes[1, 2].set_title('Channel Histograms')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Custom Color Space Analysis:\")\n",
    "for i, name in enumerate(['Intensity', 'R-G Difference', 'B-Y Difference']):\n",
    "    mean_val = np.mean(custom_channels[i])\n",
    "    std_val = np.std(custom_channels[i])\n",
    "    print(f\"{name}: Mean = {mean_val:.1f}, Std = {std_val:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aba4d9",
   "metadata": {},
   "source": [
    "### Exercise 2: Adaptive Color Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Adaptive color enhancement based on image statistics\n",
    "def adaptive_color_enhancement(image, target_mean=128, target_contrast=1.5):\n",
    "    \"\"\"Adaptively enhance image colors based on current statistics.\"\"\"\n",
    "    # Convert to LAB for better perceptual processing\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Adaptive lightness adjustment\n",
    "    current_mean = np.mean(l)\n",
    "    brightness_factor = target_mean / current_mean if current_mean > 0 else 1.0\n",
    "    l_enhanced = l * brightness_factor\n",
    "    \n",
    "    # Adaptive contrast adjustment\n",
    "    current_std = np.std(l)\n",
    "    target_std = current_std * target_contrast\n",
    "    contrast_factor = target_std / current_std if current_std > 0 else 1.0\n",
    "    \n",
    "    # Apply contrast around the mean\n",
    "    l_enhanced = (l_enhanced - current_mean) * contrast_factor + current_mean\n",
    "    \n",
    "    # Adaptive color saturation enhancement\n",
    "    a_enhanced = a * 1.2  # Boost green-red\n",
    "    b_enhanced = b * 1.2  # Boost blue-yellow\n",
    "    \n",
    "    # Clip values to valid range\n",
    "    l_enhanced = np.clip(l_enhanced, 0, 255)\n",
    "    a_enhanced = np.clip(a_enhanced, -128, 127)\n",
    "    b_enhanced = np.clip(b_enhanced, -128, 127)\n",
    "    \n",
    "    # Merge and convert back\n",
    "    enhanced_lab = cv2.merge([l_enhanced, a_enhanced, b_enhanced]).astype(np.uint8)\n",
    "    enhanced_bgr = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return enhanced_bgr\n",
    "\n",
    "# Create test images with different characteristics\n",
    "test_images = []\n",
    "\n",
    "# Dark image\n",
    "dark_image = (image * 0.3).astype(np.uint8)\n",
    "test_images.append(('Dark Image', dark_image))\n",
    "\n",
    "# Low contrast image\n",
    "low_contrast = cv2.convertScaleAbs(image, alpha=0.5, beta=50)\n",
    "test_images.append(('Low Contrast', low_contrast))\n",
    "\n",
    "# Oversaturated image\n",
    "hsv_temp = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "hsv_temp[:,:,1] *= 2.0  # Double saturation\n",
    "hsv_temp[:,:,1] = np.clip(hsv_temp[:,:,1], 0, 255)\n",
    "oversaturated = cv2.cvtColor(hsv_temp.astype(np.uint8), cv2.COLOR_HSV2BGR)\n",
    "test_images.append(('Oversaturated', oversaturated))\n",
    "\n",
    "# Apply adaptive enhancement\n",
    "fig, axes = plt.subplots(len(test_images), 3, figsize=(15, 12))\n",
    "\n",
    "for i, (name, test_img) in enumerate(test_images):\n",
    "    # Original test image\n",
    "    axes[i, 0].imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))\n",
    "    axes[i, 0].set_title(f'{name} (Original)')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Enhanced image\n",
    "    enhanced = adaptive_color_enhancement(test_img)\n",
    "    axes[i, 1].imshow(cv2.cvtColor(enhanced, cv2.COLOR_BGR2RGB))\n",
    "    axes[i, 1].set_title(f'{name} (Enhanced)')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Comparison histograms\n",
    "    gray_orig = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_enhanced = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    axes[i, 2].hist(gray_orig.ravel(), bins=50, alpha=0.7, label='Original')\n",
    "    axes[i, 2].hist(gray_enhanced.ravel(), bins=50, alpha=0.7, label='Enhanced')\n",
    "    axes[i, 2].set_title(f'{name} Histograms')\n",
    "    axes[i, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print enhancement statistics\n",
    "print(\"Adaptive Enhancement Results:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Image Type':<15} {'Orig Mean':<10} {'Enh Mean':<10} {'Orig Std':<10} {'Enh Std':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, test_img in test_images:\n",
    "    enhanced = adaptive_color_enhancement(test_img)\n",
    "    \n",
    "    gray_orig = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_enhanced = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    orig_mean = np.mean(gray_orig)\n",
    "    enh_mean = np.mean(gray_enhanced)\n",
    "    orig_std = np.std(gray_orig)\n",
    "    enh_std = np.std(gray_enhanced)\n",
    "    \n",
    "    print(f\"{name:<15} {orig_mean:<10.1f} {enh_mean:<10.1f} {orig_std:<10.1f} {enh_std:<10.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc439b8a",
   "metadata": {},
   "source": [
    "### Exercise 3: Color Harmony Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac096f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Analyze color harmony in images\n",
    "def analyze_color_harmony(image, n_colors=5):\n",
    "    \"\"\"Analyze color harmony using dominant colors and color theory.\"\"\"\n",
    "    # Extract dominant colors using K-means\n",
    "    pixel_values = image.reshape((-1, 3))\n",
    "    pixel_values = np.float32(pixel_values)\n",
    "    \n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)\n",
    "    _, labels, centers = cv2.kmeans(pixel_values, n_colors, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    # Convert to HSV for color analysis\n",
    "    centers_rgb = centers.astype(np.uint8).reshape(-1, 1, 3)\n",
    "    centers_hsv = cv2.cvtColor(centers_rgb, cv2.COLOR_BGR2HSV).reshape(-1, 3)\n",
    "    \n",
    "    # Calculate color relationships\n",
    "    hues = centers_hsv[:, 0]\n",
    "    saturations = centers_hsv[:, 1]\n",
    "    values = centers_hsv[:, 2]\n",
    "    \n",
    "    # Analyze harmony types\n",
    "    harmony_analysis = {\n",
    "        'dominant_colors': centers,\n",
    "        'hues': hues,\n",
    "        'saturations': saturations,\n",
    "        'values': values,\n",
    "        'harmony_type': classify_harmony(hues),\n",
    "        'color_temperature': analyze_temperature(centers),\n",
    "        'contrast_level': analyze_contrast(values)\n",
    "    }\n",
    "    \n",
    "    return harmony_analysis\n",
    "\n",
    "def classify_harmony(hues):\n",
    "    \"\"\"Classify the type of color harmony.\"\"\"\n",
    "    if len(hues) < 2:\n",
    "        return \"Monochromatic\"\n",
    "    \n",
    "    # Calculate hue differences\n",
    "    hue_diffs = []\n",
    "    for i in range(len(hues)):\n",
    "        for j in range(i+1, len(hues)):\n",
    "            diff = min(abs(hues[i] - hues[j]), 180 - abs(hues[i] - hues[j]))\n",
    "            hue_diffs.append(diff)\n",
    "    \n",
    "    avg_diff = np.mean(hue_diffs)\n",
    "    \n",
    "    if avg_diff < 30:\n",
    "        return \"Analogous\"\n",
    "    elif any(diff > 150 for diff in hue_diffs):\n",
    "        return \"Complementary\"\n",
    "    elif any(60 < diff < 90 for diff in hue_diffs):\n",
    "        return \"Triadic\"\n",
    "    else:\n",
    "        return \"Complex\"\n",
    "\n",
    "def analyze_temperature(colors):\n",
    "    \"\"\"Analyze overall color temperature.\"\"\"\n",
    "    # Convert BGR to RGB for analysis\n",
    "    rgb_colors = colors[:, [2, 1, 0]]\n",
    "    \n",
    "    # Calculate color temperature based on red/blue balance\n",
    "    red_avg = np.mean(rgb_colors[:, 0])\n",
    "    blue_avg = np.mean(rgb_colors[:, 2])\n",
    "    \n",
    "    if red_avg > blue_avg + 20:\n",
    "        return \"Warm\"\n",
    "    elif blue_avg > red_avg + 20:\n",
    "        return \"Cool\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "def analyze_contrast(values):\n",
    "    \"\"\"Analyze contrast level.\"\"\"\n",
    "    value_range = np.max(values) - np.min(values)\n",
    "    \n",
    "    if value_range > 150:\n",
    "        return \"High\"\n",
    "    elif value_range > 75:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "# Analyze color harmony in test image\n",
    "harmony_info = analyze_color_harmony(image, n_colors=6)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Original image\n",
    "axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Color palette\n",
    "palette_height = 100\n",
    "palette_width = 300\n",
    "palette = np.zeros((palette_height, palette_width, 3), dtype=np.uint8)\n",
    "\n",
    "n_colors = len(harmony_info['dominant_colors'])\n",
    "color_width = palette_width // n_colors\n",
    "\n",
    "for i, color in enumerate(harmony_info['dominant_colors']):\n",
    "    start_x = i * color_width\n",
    "    end_x = (i + 1) * color_width\n",
    "    palette[:, start_x:end_x] = color[::-1]  # BGR to RGB\n",
    "\n",
    "axes[0, 1].imshow(palette)\n",
    "axes[0, 1].set_title('Dominant Color Palette')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Hue distribution\n",
    "axes[0, 2].bar(range(len(harmony_info['hues'])), harmony_info['hues'])\n",
    "axes[0, 2].set_title('Hue Distribution')\n",
    "axes[0, 2].set_xlabel('Color Index')\n",
    "axes[0, 2].set_ylabel('Hue Value')\n",
    "\n",
    "# Saturation vs Value plot\n",
    "axes[1, 0].scatter(harmony_info['saturations'], harmony_info['values'], \n",
    "                   c=range(len(harmony_info['saturations'])), cmap='viridis', s=100)\n",
    "axes[1, 0].set_xlabel('Saturation')\n",
    "axes[1, 0].set_ylabel('Value')\n",
    "axes[1, 0].set_title('Saturation vs Value')\n",
    "\n",
    "# Color wheel representation\n",
    "theta = np.linspace(0, 2*np.pi, 180)\n",
    "axes[1, 1].set_theta_zero_location('N')\n",
    "axes[1, 1] = plt.subplot(2, 3, 5, projection='polar')\n",
    "\n",
    "# Plot hues on color wheel\n",
    "hue_angles = harmony_info['hues'] * 2 * np.pi / 180\n",
    "for i, (angle, sat, val) in enumerate(zip(hue_angles, harmony_info['saturations'], harmony_info['values'])):\n",
    "    axes[1, 1].scatter(angle, sat, s=val*2, alpha=0.7, label=f'Color {i+1}')\n",
    "\n",
    "axes[1, 1].set_title('Color Wheel Distribution')\n",
    "axes[1, 1].set_ylim(0, 255)\n",
    "\n",
    "# Harmony analysis text\n",
    "analysis_text = f\"\"\"\n",
    "Color Harmony Analysis:\n",
    "\n",
    "Harmony Type: {harmony_info['harmony_type']}\n",
    "Color Temperature: {harmony_info['color_temperature']}\n",
    "Contrast Level: {harmony_info['contrast_level']}\n",
    "\n",
    "Number of Dominant Colors: {len(harmony_info['dominant_colors'])}\n",
    "\n",
    "Hue Range: {np.min(harmony_info['hues']):.0f}° - {np.max(harmony_info['hues']):.0f}°\n",
    "Saturation Range: {np.min(harmony_info['saturations']):.0f} - {np.max(harmony_info['saturations']):.0f}\n",
    "Value Range: {np.min(harmony_info['values']):.0f} - {np.max(harmony_info['values']):.0f}\n",
    "\"\"\"\n",
    "\n",
    "axes[1, 2].text(0.1, 0.5, analysis_text, fontsize=10, verticalalignment='center')\n",
    "axes[1, 2].set_title('Harmony Analysis')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed analysis\n",
    "print(\"Detailed Color Harmony Analysis:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Harmony Type: {harmony_info['harmony_type']}\")\n",
    "print(f\"Color Temperature: {harmony_info['color_temperature']}\")\n",
    "print(f\"Contrast Level: {harmony_info['contrast_level']}\")\n",
    "print(f\"Number of Dominant Colors: {len(harmony_info['dominant_colors'])}\")\n",
    "print(\"\\nDominant Colors (BGR):\")\n",
    "for i, color in enumerate(harmony_info['dominant_colors']):\n",
    "    print(f\"  Color {i+1}: ({color[0]:.0f}, {color[1]:.0f}, {color[2]:.0f})\")\n",
    "print(f\"\\nHue Distribution: {harmony_info['hues']}\")\n",
    "print(f\"Saturation Distribution: {harmony_info['saturations']}\")\n",
    "print(f\"Value Distribution: {harmony_info['values']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6ea76",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we explored:\n",
    "\n",
    "1. **Color Space Conversions**: RGB, HSV, LAB, and grayscale conversions\n",
    "2. **Histogram Analysis**: Color histograms, equalization, and CLAHE\n",
    "3. **Color Enhancement**: Brightness/contrast adjustment, gamma correction, white balance\n",
    "4. **Color-based Segmentation**: HSV range segmentation and K-means clustering\n",
    "5. **Practical Applications**: Skin detection, color tracking, and object segmentation\n",
    "6. **Advanced Techniques**: Custom color spaces, adaptive enhancement, and harmony analysis\n",
    "\n",
    "### Key Takeaways:\n",
    "- Different color spaces are suitable for different tasks\n",
    "- HSV is excellent for color-based segmentation\n",
    "- LAB provides perceptually uniform color differences\n",
    "- Histogram analysis reveals image characteristics\n",
    "- Color enhancement can dramatically improve image quality\n",
    "- Color-based methods enable robust object detection and tracking\n",
    "\n",
    "### Best Practices:\n",
    "- Choose appropriate color space for your specific task\n",
    "- Use HSV for color-based segmentation and filtering\n",
    "- Apply histogram equalization carefully to avoid over-enhancement\n",
    "- Consider perceptual color spaces (LAB) for color matching\n",
    "- Combine multiple color spaces for robust detection\n",
    "- Test color-based algorithms across different lighting conditions\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different color spaces for your applications\n",
    "- Try color-based segmentation on real-world images\n",
    "- Implement advanced color enhancement algorithms\n",
    "- Explore color constancy and white balance techniques\n",
    "- Apply color analysis to artistic and design applications\n",
    "- Combine color processing with machine learning for better results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
